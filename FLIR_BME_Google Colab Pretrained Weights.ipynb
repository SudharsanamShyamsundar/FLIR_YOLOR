{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erBMpTfSdG03",
        "outputId": "c70dec5d-879e-4e5e-c631-97d0e4334252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 13 16:03:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "#https://stackoverflow.com/questions/49311195/how-to-install-coco-pythonapi-in-python3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Datasets\n"
      ],
      "metadata": {
        "id": "zDgCaW6w7Qg7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WCmJg4sC6aaT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSAV8kx5zFR",
        "outputId": "2ab15048-2d22-4492-8ba0-226edb4d9c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yolo-flir.zip to /content\n",
            "100% 6.58G/6.58G [00:41<00:00, 173MB/s]\n",
            "100% 6.58G/6.58G [00:41<00:00, 171MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d benceveges/yolo-flir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "laHran436qlG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!unzip yolo-flir.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_iMbKtk-aq5",
        "outputId": "7a219f66-8dd4-4d8c-e6b8-cb244af663ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FLIR_YOLOR'...\n",
            "remote: Enumerating objects: 2432, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 2432 (delta 1), reused 8 (delta 1), pack-reused 2424\u001b[K\n",
            "Receiving objects: 100% (2432/2432), 444.35 MiB | 31.39 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SudharsanamShyamsundar/FLIR_YOLOR.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7xQykH18B7ud"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "#Thermal Train images\n",
        "for file_name in os.listdir('/content/images_thermal_train/images_thermal_train/'):\n",
        "    # construct full file path\n",
        "    source = '/content/images_thermal_train/images_thermal_train/' + file_name\n",
        "    destination = '/content/FLIR_YOLOR/flir_f1/images/train/' + file_name\n",
        "    # move only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "# thermal train label\n",
        "for file_name in os.listdir('/content/labels/coco_thermal_train/'):\n",
        "    # construct full file path\n",
        "    source = '/content/labels/coco_thermal_train/' + file_name\n",
        "    destination = '/content/FLIR_YOLOR/flir_f1/labels/train/' + file_name\n",
        "    # move only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "# Thermal val images\n",
        "for file_name in os.listdir('/content/images_thermal_val/images_thermal_val/'):\n",
        "    # construct full file path\n",
        "    source = '/content/images_thermal_val/images_thermal_val/' + file_name\n",
        "    destination = '/content/FLIR_YOLOR/flir_f1/images/val/' + file_name\n",
        "    # move only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "# thermal validation label set\n",
        "for file_name in os.listdir('/content/labels/coco_thermal_val/'):\n",
        "    # construct full file path\n",
        "    source = '/content/labels/coco_thermal_val/' + file_name\n",
        "    destination = '/content/FLIR_YOLOR/flir_f1/labels/val/' + file_name\n",
        "    # move only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "        \n",
        "# Thermal test images\n",
        "for file_name in os.listdir('/content/video_thermal_test/video_thermal_test/'):\n",
        "    # construct full file path\n",
        "    source = '/content/video_thermal_test/video_thermal_test/' + file_name\n",
        "    destination = '/content/FLIR_YOLOR/flir_f1/images/test/' + file_name\n",
        "    # move only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.move(source, destination)\n",
        "\n",
        "# thermal test label set\n",
        "for file_name in os.listdir('/content/labels/coco_thermal_test/'):\n",
        "    # construct full file path\n",
        "    source = '/content/labels/coco_thermal_test/' + file_name\n",
        "    destination = '/content/FLIR_YOLOR/flir_f1/labels/test/' + file_name\n",
        "    # move only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.move(source, destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pklBA_ig-06f",
        "outputId": "e5f808df-954b-48f1-e92c-7bb92dcb1842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FLIR_YOLOR\n"
          ]
        }
      ],
      "source": [
        "%cd FLIR_YOLOR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xpG1rjc-_gr",
        "outputId": "86638ed7-25a9-4fe1-d50a-8e3cf8987f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 596 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.7 kB/s \n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 22.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 33.9 MB/s \n",
            "\u001b[?25h  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Czsu3t_BFg",
        "outputId": "7bb5a206-bfc4-434f-c85c-ebc9e1451ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mish-cuda'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (195/195), 208.77 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "/content/FLIR_YOLOR/mish-cuda\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U1282HDE_hls"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!python setup.py build install\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMQrh7ma_kIm",
        "outputId": "631d1b50-5db7-488b-f6d4-c186a12260a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch_wavelets'...\n",
            "remote: Enumerating objects: 972, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 972 (delta 75), reused 89 (delta 45), pack-reused 836\u001b[K\n",
            "Receiving objects: 100% (972/972), 6.80 MiB | 21.96 MiB/s, done.\n",
            "Resolving deltas: 100% (659/659), done.\n",
            "/content/FLIR_YOLOR/pytorch_wavelets\n",
            "Processing /content/FLIR_YOLOR/pytorch_wavelets\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (4.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.6)\n",
            "Building wheels for collected packages: pytorch-wavelets\n",
            "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54869 sha256=709bb1d02377396dd5001c4ebd8aaa3f2bff558eb8dd35bc0e3b12e23c757667\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-563jbvz9/wheels/0c/63/25/f2e3e824f80a8bbcdd739f12d7ed9057ea8f4c467b53eac2ea\n",
            "Successfully built pytorch-wavelets\n",
            "Installing collected packages: pytorch-wavelets\n",
            "Successfully installed pytorch-wavelets-1.3.0\n",
            "/content/FLIR_YOLOR\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "%cd pytorch_wavelets\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFYkiE3y_wT6",
        "outputId": "5d677626-9fa9-4671-aae8-1b5b49b4e8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'FLIR_YOLOR'\n",
            "/content/FLIR_YOLOR\n"
          ]
        }
      ],
      "source": [
        "%cd FLIR_YOLOR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training The Model\n"
      ],
      "metadata": {
        "id": "YM2ckXpCLQks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload the pretrained Weights from the distrubted dataset\n",
        "! kaggle datasets download -d shyamsundaravce/bestweights-10-epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BiJ56w_s6Vi",
        "outputId": "37f1a01f-bdd2-4402-e393-e03606697bbb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bestweights-10-epochs.zip to /content/FLIR_YOLOR\n",
            " 93% 201M/216M [00:01<00:00, 143MB/s]\n",
            "100% 216M/216M [00:01<00:00, 129MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/FLIR_YOLOR/bestweights-10-epochs.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ch86aZ2Ml_V",
        "outputId": "f856d222-7323-486c-aa1a-c30a97e0c3d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/FLIR_YOLOR/bestweights-10-epochs.zip\n",
            "  inflating: last.pt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDv8qm1N_8gr",
        "outputId": "1c5ea308-921a-4d5f-e379-eccbed1641bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.7.0 CUDA:0 (Tesla T4, 15109MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=4, bucket='', cache_images=False, cfg='cfg/yolor_p6.cfg', data='flir.yaml', device='0', epochs=2, evolve=False, exist_ok=False, global_rank=-1, hyp='/content/FLIR_YOLOR/data/hyp.finetune.1280.yaml', image_weights=False, img_size=[1280, 1280], local_rank=-1, log_imgs=16, multi_scale=False, name='yolor_p6', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs/train/yolor_p6', single_cls=False, sync_bn=False, total_batch_size=4, weights='/content/FLIR_YOLOR/bestweights-10-epochs.zip', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "NumExpr defaulting to 2 threads.\n",
            "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.8, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.2}\n",
            "Model Summary: 665 layers, 37265016 parameters, 37265016 gradients, 81.564040600 GFLOPS\n",
            "Optimizer groups: 145 .bias, 145 conv.weight, 149 other\n",
            "Scanning images: 100% 10478/10478 [00:13<00:00, 755.58it/s]\n",
            "Scanning labels /content/FLIR_YOLOR/flir_f1/labels/train.cache3 (10478 found, 0 missing, 0 empty, 2 duplicate, for 10478 images): 10478it [00:00, 14396.04it/s]\n",
            "Scanning images: 100% 1128/1128 [00:01<00:00, 666.33it/s]\n",
            "Scanning labels /content/FLIR_YOLOR/flir_f1/labels/val.cache3 (1128 found, 0 missing, 0 empty, 2 duplicate, for 1128 images): 1128it [00:00, 15432.91it/s]\n",
            "Image sizes 1280 train, 1280 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolor_p6\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "       0/1     9.96G   0.08958   0.04399   0.07047     0.204        38      1280: 100% 2620/2620 [28:19<00:00,  1.54it/s]\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "       1/1       10G   0.08263   0.03975   0.04394    0.1663        63      1280: 100% 2620/2620 [27:38<00:00,  1.58it/s]\n",
            "Optimizer stripped from runs/train/yolor_p6/weights/last.pt, 149.6MB\n",
            "Optimizer stripped from runs/train/yolor_p6/weights/best.pt, 149.6MB\n",
            "2 epochs completed in 0.938 hours.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python train.py --batch-size 4 --img 1280 1280 --data flir.yaml --cfg cfg/yolor_p6.cfg --weights '/content/FLIR_YOLOR/bestweights-10-epochs.zip' --device 0 --name yolor_p6 --hyp '/content/FLIR_YOLOR/data/hyp.finetune.1280.yaml' --epochs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlDwDhJgsQI9"
      },
      "outputs": [],
      "source": [
        "#!python -m torch.distributed.launch --nproc_per_node 4 --master_port 9527 train.py --batch-size 16 --img 1280 1280 --data flir.yaml --cfg cfg/yolor_p6.cfg --weights '' --device 0,1,2,3 --sync-bn --name yolor_p6 --hyp '/content/FLIR_YOLOR/data/hyp.scratch.1280.yaml' --epochs 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detection and Testing"
      ],
      "metadata": {
        "id": "TEgkLhKSjvtX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Jaoj7_TrnkWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65ba710-7fb7-49e2-8116-81dde3b3ad5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, cfg='cfg/yolor_p6.cfg', classes=None, conf_thres=0.25, device='', img_size=1280, iou_thres=0.5, names='/content/FLIR_YOLOR/data/coco.names', output='inference/output', save_txt=False, source='/content/FLIR_YOLOR/flir_f1/images/test/video-4FRnNpmSmwktFJKjg-frame-000745-L6K5SC6fYjHNC8uff.jpg', update=False, view_img=False, weights=['/content/FLIR_YOLOR/last.pt'])\n",
            "image 1/1 /content/FLIR_YOLOR/flir_f1/images/test/video-4FRnNpmSmwktFJKjg-frame-000745-L6K5SC6fYjHNC8uff.jpg: 1024x1280 1 persons, 1 cars, Done. (0.267s)\n",
            "Results saved to inference/output\n",
            "Done. (0.676s)\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --weights /content/FLIR_YOLOR/last.pt --conf 0.25 --source /content/FLIR_YOLOR/flir_f1/images/test/video-4FRnNpmSmwktFJKjg-frame-000745-L6K5SC6fYjHNC8uff.jpg --names /content/FLIR_YOLOR/data/coco.names --cfg cfg/yolor_p6.cfg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --data flir.yaml --img 1280 --batch 16 --conf 0.001 --iou 0.65 --device 0 --cfg cfg/yolor_p6.cfg --weights /content/FLIR_YOLOR/last.pt --name yolor_p6_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyhZjisjspna",
        "outputId": "04029a85-10f8-4126-a297-10a399848a2e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(augment=False, batch_size=16, cfg='cfg/yolor_p6.cfg', conf_thres=0.001, data='flir.yaml', device='0', exist_ok=False, img_size=1280, iou_thres=0.65, name='yolor_p6_val', names='data/coco.names', project='runs/test', save_conf=False, save_json=False, save_txt=False, single_cls=False, task='val', verbose=False, weights=['/content/FLIR_YOLOR/last.pt'])\n",
            "Using torch 1.7.0 CUDA:0 (Tesla K80, 11441MB)\n",
            "\n",
            "Model Summary: 665 layers, 37265016 parameters, 37265016 gradients, 81.564040600 GFLOPS\n",
            "Scanning labels /content/FLIR_YOLOR/flir_f1/labels/val.cache3 (1128 found, 0 missing, 0 empty, 2 duplicate, for 1128 images): 1128it [00:00, 9341.42it/s]\n",
            "               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 71/71 [05:11<00:00,  4.39s/it]\n",
            "                 all    1.13e+03    1.67e+04       0.248        0.39        0.32       0.169\n",
            "Speed: 256.7/3.9/260.6 ms inference/NMS/total per 1280x1280 image at batch-size 16\n",
            "Results saved to runs/test/yolor_p6_val30\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FLIR_BME (2) (1) (1).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}